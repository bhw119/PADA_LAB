{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284b96b3-33a4-4e3a-b303-22db317c87f4",
   "metadata": {},
   "source": [
    "# hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad65f15c-b890-487f-91f2-8847858d0de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "room small nice bed hotel clean bathroom comfortable didnt shower\n",
      "\n",
      "Topic 2:\n",
      "location perfect excellent central amazing cleanliness rooms fantastic ok price\n",
      "\n",
      "Topic 3:\n",
      "staff friendly helpful excellent clean lovely hotel comfortable rooms breakfast\n",
      "\n",
      "Topic 4:\n",
      "good breakfast value food money hotel bit choice nice beds\n",
      "\n",
      "Topic 5:\n",
      "great value clean comfortable lovely customer attentive stay money rooms\n",
      "\n",
      "Topic distribution with depth and breadth added to 'hotel_reviews_with_topics_and_depth_breadth.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv(\"/Users/hyunwoo/Desktop/PADA/PADA_LAB/raw/hotel.csv\")\n",
    "\n",
    "# 텍스트 데이터를 전처리\n",
    "df['Review_Text'] = df['Review_Text'].fillna('')\n",
    "\n",
    "# 텍스트 데이터를 TF-IDF 벡터로 변환\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X = vectorizer.fit_transform(df['Review_Text'])\n",
    "\n",
    "# NMF 모델을 사용하여 주제 모델링 수행\n",
    "num_topics = 5  # 원하는 주제의 개수 설정\n",
    "nmf = NMF(n_components=num_topics, random_state=42)\n",
    "nmf.fit(X)\n",
    "\n",
    "# 각 주제에 대한 단어 목록 출력\n",
    "terms = np.array(vectorizer.get_feature_names_out())\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(f\"Topic {topic_idx + 1}:\")\n",
    "    print(\" \".join([terms[i] for i in topic.argsort()[:-11:-1]]))\n",
    "    print()\n",
    "\n",
    "# 주제기여도를 0이면 아주 작은 값으로 대체 (0.00000000000000001)\n",
    "topic_contributions = nmf.transform(X)\n",
    "topic_contributions = np.maximum(topic_contributions, 1e-20)  # 0을 매우 작은 값으로 대체\n",
    "\n",
    "# 'depth' 열 추가: log10을 씌운 주제기여도 합산\n",
    "depth = np.sum(np.log10(topic_contributions), axis=1)\n",
    "\n",
    "# 주제 기여도의 합을 1로 정규화\n",
    "topic_contributions_normalized = topic_contributions / topic_contributions.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# KL Divergence 계산 함수 (Breadth 계산)\n",
    "def calculate_kl_divergence(review_topic_proportions, global_topic_proportions):\n",
    "    # 0이 발생하지 않도록 작은 값 추가\n",
    "    review_topic_proportions = review_topic_proportions + 1e-10\n",
    "    global_topic_proportions = global_topic_proportions + 1e-10\n",
    "    \n",
    "    # KL 발산 계산\n",
    "    kl_divergence = np.sum(review_topic_proportions * np.log2(review_topic_proportions / global_topic_proportions))\n",
    "    \n",
    "    # NaN 또는 Inf 값이 발생할 경우 0으로 처리\n",
    "    if np.isnan(kl_divergence) or np.isinf(kl_divergence):\n",
    "        return np.nan  # NaN이나 Inf일 경우 NaN 반환\n",
    "    else:\n",
    "        return kl_divergence\n",
    "\n",
    "# 전체 문서에 대한 주제 비율의 평균 계산 (global_topic_proportions)\n",
    "global_topic_proportions = np.mean(topic_contributions_normalized, axis=0)\n",
    "\n",
    "# 각 문서에 대해 KL 발산(Breadth) 계산\n",
    "breadth = np.apply_along_axis(lambda x: calculate_kl_divergence(x, global_topic_proportions), axis=1, arr=topic_contributions_normalized)\n",
    "\n",
    "# DataFrame에 depth와 breadth 추가\n",
    "df['depth'] = np.sum(np.log10(topic_contributions), axis=1)\n",
    "df['breadth'] = breadth\n",
    "\n",
    "# 주제 기여도 정규화된 값도 DataFrame에 추가\n",
    "for i in range(num_topics):\n",
    "    df[f\"Topic_{i+1}\"] = topic_contributions_normalized[:, i]\n",
    "\n",
    "# 정규화된 결과를 CSV로 저장\n",
    "df.to_csv('hotel_reviews_with_topics_and_depth_breadth.csv', index=False)\n",
    "\n",
    "print(\"Topic distribution with depth and breadth added to 'hotel_reviews_with_topics_and_depth_breadth.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98304024-2ff0-4f5c-9d7a-550058f62fe9",
   "metadata": {},
   "source": [
    "# amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06067326-31b2-40d8-9c88-3f7729ce00ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "great product price sound quality value worked buy sounds fast\n",
      "\n",
      "Topic 2:\n",
      "good quality product price sound value far really pretty money\n",
      "\n",
      "Topic 3:\n",
      "works perfectly expected fine advertised perfect great described just exactly\n",
      "\n",
      "Topic 4:\n",
      "work love like just sound mouse tv use bought quality\n",
      "\n",
      "Topic 5:\n",
      "easy install use set mount tv sturdy setup super wall\n",
      "\n",
      "Topic distribution with depth and breadth added to 'amazon_reviews_with_topics_and_depth_breadth.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv(\"/Users/hyunwoo/Desktop/PADA/PADA_LAB/raw/amazon.csv\")\n",
    "\n",
    "# 텍스트 데이터를 전처리\n",
    "df['Review_Text'] = df['Review_Text'].fillna('')\n",
    "\n",
    "# 텍스트 데이터를 TF-IDF 벡터로 변환\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X = vectorizer.fit_transform(df['Review_Text'])\n",
    "\n",
    "# NMF 모델을 사용하여 주제 모델링 수행\n",
    "num_topics = 5  # 원하는 주제의 개수 설정\n",
    "nmf = NMF(n_components=num_topics, random_state=42)\n",
    "nmf.fit(X)\n",
    "\n",
    "# 각 주제에 대한 단어 목록 출력\n",
    "terms = np.array(vectorizer.get_feature_names_out())\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(f\"Topic {topic_idx + 1}:\")\n",
    "    print(\" \".join([terms[i] for i in topic.argsort()[:-11:-1]]))\n",
    "    print()\n",
    "\n",
    "# 주제기여도를 0이면 아주 작은 값으로 대체 (0.00000000000000001)\n",
    "topic_contributions = nmf.transform(X)\n",
    "topic_contributions = np.maximum(topic_contributions, 1e-20)  # 0을 매우 작은 값으로 대체\n",
    "\n",
    "# 'depth' 열 추가: log10을 씌운 주제기여도 합산\n",
    "depth = np.sum(np.log10(topic_contributions), axis=1)\n",
    "\n",
    "# 주제 기여도의 합을 1로 정규화\n",
    "topic_contributions_normalized = topic_contributions / topic_contributions.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# KL Divergence 계산 함수 (Breadth 계산)\n",
    "def calculate_kl_divergence(review_topic_proportions, global_topic_proportions):\n",
    "    # 0이 발생하지 않도록 작은 값 추가\n",
    "    review_topic_proportions = review_topic_proportions + 1e-10\n",
    "    global_topic_proportions = global_topic_proportions + 1e-10\n",
    "    \n",
    "    # KL 발산 계산\n",
    "    kl_divergence = np.sum(review_topic_proportions * np.log2(review_topic_proportions / global_topic_proportions))\n",
    "    \n",
    "    # NaN 또는 Inf 값이 발생할 경우 0으로 처리\n",
    "    if np.isnan(kl_divergence) or np.isinf(kl_divergence):\n",
    "        return np.nan  # NaN이나 Inf일 경우 NaN 반환\n",
    "    else:\n",
    "        return kl_divergence\n",
    "\n",
    "# 전체 문서에 대한 주제 비율의 평균 계산 (global_topic_proportions)\n",
    "global_topic_proportions = np.mean(topic_contributions_normalized, axis=0)\n",
    "\n",
    "# 각 문서에 대해 KL 발산(Breadth) 계산\n",
    "breadth = np.apply_along_axis(lambda x: calculate_kl_divergence(x, global_topic_proportions), axis=1, arr=topic_contributions_normalized)\n",
    "\n",
    "# DataFrame에 depth와 breadth 추가\n",
    "df['depth'] = np.sum(np.log10(topic_contributions), axis=1)\n",
    "df['breadth'] = breadth\n",
    "\n",
    "# 주제 기여도 정규화된 값도 DataFrame에 추가\n",
    "for i in range(num_topics):\n",
    "    df[f\"Topic_{i+1}\"] = topic_contributions_normalized[:, i]\n",
    "\n",
    "# 정규화된 결과를 CSV로 저장\n",
    "df.to_csv('amazon_reviews_with_topics_and_depth_breadth.csv', index=False)\n",
    "\n",
    "print(\"Topic distribution with depth and breadth added to 'amazon_reviews_with_topics_and_depth_breadth.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f261b6ef-caac-4e53-9509-722d732469a7",
   "metadata": {},
   "source": [
    "# audible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6c49696-bd47-46c9-acea-a8c7cfa0546b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "book recommend like just love listening really life highly good\n",
      "\n",
      "Topic 2:\n",
      "story characters love really good enjoyed life like narration narrator\n",
      "\n",
      "Topic 3:\n",
      "great listen job narrator narration performance does did fun recommend\n",
      "\n",
      "Topic 4:\n",
      "loved absolutely listening minute recommend wait characters narration amazing narrator\n",
      "\n",
      "Topic 5:\n",
      "read ive books best time listened listen written years times\n",
      "\n",
      "Topic distribution with depth and breadth added to 'amazon_reviews_with_topics_and_depth_breadth.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv(\"/Users/hyunwoo/Desktop/PADA/PADA_LAB/raw/audible.csv\")\n",
    "\n",
    "# 텍스트 데이터를 전처리\n",
    "df['Review_Text'] = df['Review_Text'].fillna('')\n",
    "\n",
    "# 텍스트 데이터를 TF-IDF 벡터로 변환\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X = vectorizer.fit_transform(df['Review_Text'])\n",
    "\n",
    "# NMF 모델을 사용하여 주제 모델링 수행\n",
    "num_topics = 5  # 원하는 주제의 개수 설정\n",
    "nmf = NMF(n_components=num_topics, random_state=42)\n",
    "nmf.fit(X)\n",
    "\n",
    "# 각 주제에 대한 단어 목록 출력\n",
    "terms = np.array(vectorizer.get_feature_names_out())\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(f\"Topic {topic_idx + 1}:\")\n",
    "    print(\" \".join([terms[i] for i in topic.argsort()[:-11:-1]]))\n",
    "    print()\n",
    "\n",
    "# 주제기여도를 0이면 아주 작은 값으로 대체 (0.00000000000000001)\n",
    "topic_contributions = nmf.transform(X)\n",
    "topic_contributions = np.maximum(topic_contributions, 1e-20)  # 0을 매우 작은 값으로 대체\n",
    "\n",
    "# 'depth' 열 추가: log10을 씌운 주제기여도 합산\n",
    "depth = np.sum(np.log10(topic_contributions), axis=1)\n",
    "\n",
    "# 주제 기여도의 합을 1로 정규화\n",
    "topic_contributions_normalized = topic_contributions / topic_contributions.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# KL Divergence 계산 함수 (Breadth 계산)\n",
    "def calculate_kl_divergence(review_topic_proportions, global_topic_proportions):\n",
    "    # 0이 발생하지 않도록 작은 값 추가\n",
    "    review_topic_proportions = review_topic_proportions + 1e-10\n",
    "    global_topic_proportions = global_topic_proportions + 1e-10\n",
    "    \n",
    "    # KL 발산 계산\n",
    "    kl_divergence = np.sum(review_topic_proportions * np.log2(review_topic_proportions / global_topic_proportions))\n",
    "    \n",
    "    # NaN 또는 Inf 값이 발생할 경우 0으로 처리\n",
    "    if np.isnan(kl_divergence) or np.isinf(kl_divergence):\n",
    "        return np.nan  # NaN이나 Inf일 경우 NaN 반환\n",
    "    else:\n",
    "        return kl_divergence\n",
    "\n",
    "# 전체 문서에 대한 주제 비율의 평균 계산 (global_topic_proportions)\n",
    "global_topic_proportions = np.mean(topic_contributions_normalized, axis=0)\n",
    "\n",
    "# 각 문서에 대해 KL 발산(Breadth) 계산\n",
    "breadth = np.apply_along_axis(lambda x: calculate_kl_divergence(x, global_topic_proportions), axis=1, arr=topic_contributions_normalized)\n",
    "\n",
    "# DataFrame에 depth와 breadth 추가\n",
    "df['depth'] = np.sum(np.log10(topic_contributions), axis=1)\n",
    "df['breadth'] = breadth\n",
    "\n",
    "# 주제 기여도 정규화된 값도 DataFrame에 추가\n",
    "for i in range(num_topics):\n",
    "    df[f\"Topic_{i+1}\"] = topic_contributions_normalized[:, i]\n",
    "\n",
    "# 정규화된 결과를 CSV로 저장\n",
    "df.to_csv('audible_reviews_with_topics_and_depth_breadth.csv', index=False)\n",
    "\n",
    "print(\"Topic distribution with depth and breadth added to 'amazon_reviews_with_topics_and_depth_breadth.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cb2fdb-59d8-4df2-aa28-7d9050349b2e",
   "metadata": {},
   "source": [
    "# coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ca5b73c-cdbc-4c75-8a33-f33161649884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "good course beginners experience introduction content start explanation learning teaching\n",
      "\n",
      "Topic 2:\n",
      "great course experience learning introduction content teacher instructor start intro\n",
      "\n",
      "Topic 3:\n",
      "course really amazing best thank learn lot python awesome programming\n",
      "\n",
      "Topic 4:\n",
      "excellent course teaching content instructor teacher introduction beginners material explanation\n",
      "\n",
      "Topic 5:\n",
      "nice course experience introduction explanation teaching content learning beginners teacher\n",
      "\n",
      "Topic distribution with depth and breadth added to 'coursera_reviews_with_topics_and_depth_breadth.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv(\"/Users/hyunwoo/Desktop/PADA/PADA_LAB/raw/coursera.csv\", encoding = 'cp949')\n",
    "\n",
    "# 텍스트 데이터를 전처리\n",
    "df['Review_Text'] = df['Review_Text'].fillna('')\n",
    "\n",
    "# 텍스트 데이터를 TF-IDF 벡터로 변환\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X = vectorizer.fit_transform(df['Review_Text'])\n",
    "\n",
    "# NMF 모델을 사용하여 주제 모델링 수행\n",
    "num_topics = 5  # 원하는 주제의 개수 설정\n",
    "nmf = NMF(n_components=num_topics, random_state=42)\n",
    "nmf.fit(X)\n",
    "\n",
    "# 각 주제에 대한 단어 목록 출력\n",
    "terms = np.array(vectorizer.get_feature_names_out())\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(f\"Topic {topic_idx + 1}:\")\n",
    "    print(\" \".join([terms[i] for i in topic.argsort()[:-11:-1]]))\n",
    "    print()\n",
    "\n",
    "# 주제기여도를 0이면 아주 작은 값으로 대체 (0.00000000000000001)\n",
    "topic_contributions = nmf.transform(X)\n",
    "topic_contributions = np.maximum(topic_contributions, 1e-20)  # 0을 매우 작은 값으로 대체\n",
    "\n",
    "# 'depth' 열 추가: log10을 씌운 주제기여도 합산\n",
    "depth = np.sum(np.log10(topic_contributions), axis=1)\n",
    "\n",
    "# 주제 기여도의 합을 1로 정규화\n",
    "topic_contributions_normalized = topic_contributions / topic_contributions.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# KL Divergence 계산 함수 (Breadth 계산)\n",
    "def calculate_kl_divergence(review_topic_proportions, global_topic_proportions):\n",
    "    # 0이 발생하지 않도록 작은 값 추가\n",
    "    review_topic_proportions = review_topic_proportions + 1e-10\n",
    "    global_topic_proportions = global_topic_proportions + 1e-10\n",
    "    \n",
    "    # KL 발산 계산\n",
    "    kl_divergence = np.sum(review_topic_proportions * np.log2(review_topic_proportions / global_topic_proportions))\n",
    "    \n",
    "    # NaN 또는 Inf 값이 발생할 경우 0으로 처리\n",
    "    if np.isnan(kl_divergence) or np.isinf(kl_divergence):\n",
    "        return np.nan  # NaN이나 Inf일 경우 NaN 반환\n",
    "    else:\n",
    "        return kl_divergence\n",
    "\n",
    "# 전체 문서에 대한 주제 비율의 평균 계산 (global_topic_proportions)\n",
    "global_topic_proportions = np.mean(topic_contributions_normalized, axis=0)\n",
    "\n",
    "# 각 문서에 대해 KL 발산(Breadth) 계산\n",
    "breadth = np.apply_along_axis(lambda x: calculate_kl_divergence(x, global_topic_proportions), axis=1, arr=topic_contributions_normalized)\n",
    "\n",
    "# DataFrame에 depth와 breadth 추가\n",
    "df['depth'] = np.sum(np.log10(topic_contributions), axis=1)\n",
    "df['breadth'] = breadth\n",
    "\n",
    "# 주제 기여도 정규화된 값도 DataFrame에 추가\n",
    "for i in range(num_topics):\n",
    "    df[f\"Topic_{i+1}\"] = topic_contributions_normalized[:, i]\n",
    "\n",
    "# 정규화된 결과를 CSV로 저장\n",
    "df.to_csv('coursera_reviews_with_topics_and_depth_breadth.csv', index=False)\n",
    "\n",
    "print(\"Topic distribution with depth and breadth added to 'coursera_reviews_with_topics_and_depth_breadth.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
